{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37b36e18",
   "metadata": {},
   "source": [
    "# Pre-processing and Training Data Development of Credit Card Date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677e9319",
   "metadata": {},
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94b37f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.16.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly import tools\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "from ipywidgets import widgets\n",
    "from scipy.stats import zscore\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#TRAIN/VALIDATION/TEST SPLIT\n",
    "#VALIDATION\n",
    "VALID_SIZE = 0.20 # simple validation using train_test_split\n",
    "TEST_SIZE = 0.20 # test size using_train_test_split\n",
    "\n",
    "RANDOM_STATE = 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee0e7e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0aba7fd",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92400aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
       "       'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"/Users/courtneydavid/Documents/Data Science Springboard Career Track Course/Capstone 2/creditcard.csv\")\n",
    "data_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50c3fc9",
   "metadata": {},
   "source": [
    "# Create dummy features for categorical variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ff0a3e",
   "metadata": {},
   "source": [
    "In my dataset there are no categorical features. But for the assignment I have displayed possible code if I did have categorical variables in my dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82017c66",
   "metadata": {},
   "source": [
    "dfo=data_df['Class'] \n",
    "dummy_state_values= pd.get_dummies(dfo)\n",
    "dummy_state_values\n",
    "data_df=pd.concat([data_df,dummy_state_values],axis=1)\n",
    "del(data_df['Class'])\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb73efa",
   "metadata": {},
   "source": [
    "# Standardize the magnitude of numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b9d3f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Class'\n",
    "predictors = ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\\\n",
    "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19',\\\n",
    "       'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28',\\\n",
    "       'Amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "680ebe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_response_var_data=data_df.drop(['Amount','Class'], axis=1)\n",
    "y=data_df.Class\n",
    "scaler = preprocessing.StandardScaler().fit(no_response_var_data)\n",
    "scaled=scaler.transform(no_response_var_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df20f310",
   "metadata": {},
   "source": [
    "del(data_df['Class'])\n",
    "y=data_df['Time']\n",
    "no_response_var_data=data_df.drop(data_df.loc[:,[\"Time\"]],axis=1)\n",
    "scaled=preprocessing.StandardScaler().fit(no_response_var_data)\n",
    "scaled\n",
    "X_scaled=scaled.transform(no_response_var_data) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "391b23e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_response_var_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f2ddd2",
   "metadata": {},
   "source": [
    "# Split into training and testing datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6577755",
   "metadata": {},
   "source": [
    "The data will be split into training, validation and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5204483",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(data_df, test_size=TEST_SIZE, random_state=RANDOM_STATE, shuffle=True )\n",
    "train_df, valid_df = train_test_split(train_df, test_size=VALID_SIZE, random_state=RANDOM_STATE, shuffle=True )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
